{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545bbe40",
   "metadata": {},
   "source": [
    "# COMPUTATIONAL MORPHOLOGY WITH HFST TOOLS - LECTURE 5\n",
    "\n",
    "<ul>\n",
    " <li><a href=\"#1.-Big-picture\">1. Big picture</a></li>\n",
    " <li><a href=\"#2.-Guessers-and-stemmers\">2. Guessers and stemmers</a></li>\n",
    " <li><a href=\"#3.-Pronunciation-lexicon-for-a-Language-with-(almost)-regular-Orthography:-Brazilian-Portuguese\">3. Pronunciation lexicon for a Language with (almost) regular Orthography: Brazilian Portuguese</a></li>\n",
    " <li><a href=\"#4.-Regular-expressions-in-xfst\">4. Regular expressions in xfst</a></li>\n",
    " <li><a href=\"#5.-Pronunciation-lexicon-for-a-Language-with-Irregular-Orthography:-English\">5. Pronunciation lexicon for a Language with Irregular Orthography: English</a></li>\n",
    " <li><a href=\"#6.-Sound-Change-in-Indo-European-languages\">6. Sound Change in Indo-European languages</a></li>\n",
    " <li><a href=\"#7.-Assignments\">7. Assignments</a></li>\n",
    "</ul>\n",
    "\n",
    "## 1. Big picture\n",
    "\n",
    "### 1.1. lexc\n",
    "\n",
    "\"Lexicon without any replace rules\"\n",
    "\n",
    "<img src=\"img/big_picture_lexc.png\">\n",
    "\n",
    "### 1.2. xfst and twolc\n",
    "\n",
    "\"Lexicon combined with replace rules\"\n",
    "\n",
    "<img src=\"img/big_picture_xfst_and_twolc.png\">\n",
    "\n",
    "### 1.3. xfst / regular expressions\n",
    "\n",
    "\"Rules without much of a lexicon\" \n",
    "\n",
    "<img src=\"img/big_picture_xfst_and_regexps.png\">\n",
    "\n",
    "## 2. Guessers and stemmers\n",
    "\n",
    "### 2.1. Increased coverage with guessers \n",
    "\n",
    "<ul>\n",
    "<li>Section 9.5.4 in the Beesley & Karttunen book</li>\n",
    "<li>A finite-state morphological analyzer only recognizes the words that are included in its lexc lexicon.</li>\n",
    "<li>It may take several person-months (or even years) of work to build up a lexicon with the tens of thousands of stems necessary for broad coverage of real text.</li>\n",
    "<li>As an alternative, or a complement, one can use</li>\n",
    "<ul>\n",
    "  <li>guessers</li>\n",
    "  <li>stemmers</li>\n",
    "  <li>unsupervised morphology</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "### 2.2. Definition of a guesser\n",
    "\n",
    "<ul>\n",
    "<li>A guesser is designed to analyze words that are based on any phonologically possible stem.</li>\n",
    "<li>The set of phonologically possible stems is definable, more or less precisely, using regular expressions and scripts.</li>\n",
    "<li>Useful</li>\n",
    "<ul>\n",
    "  <li>as a general backup when normal morphological analysis fails</li>\n",
    "  <li>for suggesting new stems that need to be added to the lexicon</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "### 2.3. Case study: Esperanto verb guesser lexicon\n",
    "\n",
    "<img src=\"img/esperanto_lexc.png\">\n",
    "\n",
    "### 2.4. Case study: Esperanto verb guesser xfst script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import XfstCompiler\n",
    "comp = XfstCompiler()\n",
    "script =\"\"\"\n",
    "clear stack\n",
    "\n",
    "! We limit ourselves here to lower case letters and ignore some Esperanto letters not found in the\n",
    "! ASCII character set\n",
    "define Vowel     a | e | i | o | u ;\n",
    "define ConsClust b | c | d | f | g | h | j | k | l | m | n | p | r | s | t | v | z |\n",
    "                 k r | p r | t r | g r | b r | d r | s k | s p | s t ;\n",
    "\n",
    "                 ! Each verb root must be of the format Cc V Cc V Cc V Cc ..., where the first consonant cluster Cc is\n",
    "                 ! optional and it must be followed by at least one pair of V Cc ( = vowel + consonant cluster):\n",
    "                 define PossibleVerbRoot  ( ConsClust ) [ [ Vowel ] [ ConsClust ] ]+ \"+Guess\":0 ;\n",
    "\n",
    "                 ! The lexc description is compiled and pushed on the stack\n",
    "                 read lexc esperanto.lexc\n",
    "\n",
    "                 ! Using the 'substitute defined' command, the placeholder symbol is replaced by the value of PossVerbRoot\n",
    "                 substitute defined PossibleVerbRoot for ^GUESSVERBROOT\n",
    "\n",
    "                 ! Make verb vocabulary ready to use\n",
    "                 define AllPossibleVerbs ;\n",
    "                 regex AllPossibleVerbs ;\n",
    "\"\"\"\n",
    "comp.parse_line(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bd7c5",
   "metadata": {},
   "source": [
    "### 2.5. Case study: Esperanto verb guesser example output\n",
    "\n",
    "Try the following commands:\n",
    "\n",
    "```\n",
    "up donadas     random-upper     random-lower\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.parse_line('up donadas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5d9bc",
   "metadata": {},
   "source": [
    "You should get something like this as a result for up donadas:\n",
    "\n",
    "```\n",
    "don+Guess+Verb+Cont+Pres\n",
    "don+Verb+Cont+Pres\n",
    "donad+Guess+Verb+Pres\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.parse_line('random-upper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f540ac",
   "metadata": {},
   "source": [
    "for random-upper:\n",
    "\n",
    "```\n",
    "dip+Guess+Verb+Fut\n",
    "egrust+Guess+Verb+Subj\n",
    "fust+Guess+Verb+Fut\n",
    "obr+Guess+Verb+Cont+Fut\n",
    "opop+Guess+Verb+Cond\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a41ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.parse_line('random-lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b487487",
   "metadata": {},
   "source": [
    "for random-lower:\n",
    "\n",
    "```\n",
    "etros\n",
    "hemodas\n",
    "jumadis\n",
    "soski\n",
    "tozezus\n",
    "ugrucas\n",
    "vabis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1f91e",
   "metadata": {},
   "source": [
    "### 2.6. Stemming\n",
    "\n",
    "<ul>\n",
    " <li>A term used particularly in information retrieval to describe the process of reducing inflected (or sometimes derived) words to their word stem, base or root form — generally a written word form.</li>\n",
    " <ul>\n",
    "  <li>The stem is “fish” for “fishing”, “fished”, and “fisher”.</li>\n",
    "  <li>The stem is “argu” for “argue”, “argued”, “argues”, “arguing”, and “argus”...(!)</li>\n",
    " </ul>\n",
    " <li>The stem does not need to be identical to the morphological root of the word.</li>\n",
    " <ul>\n",
    "  <li>It is sufficient that related words map to the same stem, even if this stem is not in itself a valid root, such as the stem “argu” above, or the stem “citi” for “city” and “cities”.</li>\n",
    " </ul>\n",
    " <li>Algorithms for stemming have been studied in computer science since the 1960s.</li>\n",
    " <li>Many search engines treat words with the same stem as synonyms, as a kind of query expansion, a process called conflation.</li>\n",
    "</ul>\n",
    "\n",
    "#### Porter’s stemmer (1979-1980)\n",
    "\n",
    "<ul>\n",
    " <li>Idea:</li>\n",
    " <ul>\n",
    "  <li>Remove what looks like suffixes of English words</li>\n",
    "  <li>Tidy up a bit</li>\n",
    " </ul>\n",
    " <li>Feasible for English with such “simple morphology”</li>\n",
    " <li>The full algorithm is described <a href=\"http://tartarus.org/martin/PorterStemmer/def.txt\">here</a>.</li>\n",
    " <li>There are other English stemmers:</li>\n",
    " <ul>\n",
    "  <li>Snowball</li>\n",
    "  <li>Lancaster</li>\n",
    "  <li>They are more “aggressive” than the Porter stemmer; they remove more “suffixes”.</li>\n",
    " </ul>\n",
    "</ul>\n",
    "\n",
    "<img src=\"img/porters_stemmer.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192e669",
   "metadata": {},
   "source": [
    "## 3. Pronunciation lexicon for a Language with (almost) regular Orthography: Brazilian Portuguese\n",
    "\n",
    "### 3.1. Transducing between orthographic and pronounced forms of words\n",
    "\n",
    "<ul>\n",
    " <li>Section 3.5.4 in the Beesley & Karttunen book</li>\n",
    " <li>Exercise on Portuguese Brazilian</li>\n",
    " <li>The task is to create a cascade of rules that maps from orthographical strings in Portuguese (this will be the lexical side) down to strings that represent their pronunciation (this will be the surface side).</li>\n",
    " <ul>\n",
    "  <li>There will not be a lexicon.</li>\n",
    "  <li>A sample mapping of written “caso” to spoken “kazu” looks like this:\n",
    "<pre>\n",
    "Lexical: caso\n",
    "Surface: kazu\n",
    "</pre></li>\n",
    " </ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "### 3.2. Phonetic symbols for Portuguese\n",
    "\n",
    "<img src=\"img/phonetic_symbols_for_portuguese.png\">\n",
    "\n",
    "<i>Table from Beesley & Karttunen: Finite State Morphology, CSLI Publications, 2003.</i>\n",
    "\n",
    "### 3.3. Some example words\n",
    "\n",
    "What applications that you can think of need a mapping between orthographic and pronounced forms?\n",
    "\n",
    "<img src=\"img/test_data_for_portuguese.png\">\n",
    "\n",
    "<i>Table from Beesley & Karttunen: Finite State Morphology, CSLI Publications, 2003.</i>\n",
    "\n",
    "### 3.4. Conversion from orthography to pronunciation for Brazilian Portuguese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bafada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_xfst_script\n",
    "compile_xfst_script(\n",
    "\"\"\"\n",
    "define Vowel [ a | e | i | o | u\n",
    "             | á | é | í | ó | ú\n",
    "             | â | ê |     ô\n",
    "             | ã |         õ\n",
    "             | à\n",
    "             |                 ü\n",
    "] ;\n",
    "\n",
    "define Rule1 [ s -> z || Vowel _ Vowel ];\n",
    "\n",
    "define Rule2 [ ç -> s ];\n",
    "\n",
    "define Rule3 [ c h -> %$ ];\n",
    "\n",
    "define Rule4 [ c -> s || _ [ e | i | é | í | ê ] ];\n",
    "\n",
    "define Rule5 [ c -> k ];\n",
    "\n",
    "define Rule6 [ s s -> s ];\n",
    "\n",
    "define Rule7 [ n h -> N ];\n",
    "\n",
    "define Rule8 [ l h -> L ];\n",
    "\n",
    "define Rule9 [ h -> 0 ];\n",
    "\n",
    "define Rule10 [ r r -> R ];\n",
    "\n",
    "define Rule11 [ r -> R || .#. _ ];\n",
    "\n",
    "define Rule12 [ e -> i || _ (s) .#. , .#. p _ r ];\n",
    "\n",
    "define Rule13 [ o -> u || _ (s) .#. ];\n",
    "\n",
    "define Rule14 [ d -> J || _ [ i | í ] ];\n",
    "\n",
    "define Rule15 [ t -> C || _ [ i | í ] ];\n",
    "\n",
    "define Rule16 [ z -> s || _ .#. ];\n",
    "\n",
    "read regex Rule1 .o. Rule2 .o. Rule3 .o. Rule4 .o. Rule5 .o. Rule6 .o. Rule7 .o. Rule8 .o.\n",
    "Rule9 .o. Rule10 .o. Rule11 .o. Rule12 .o. Rule13 .o. Rule14 .o. Rule15 .o. Rule16 ;\n",
    "\n",
    "invert net\n",
    "minimize net\n",
    "apply up\n",
    "disse\n",
    "simpático\n",
    "chato\n",
    "braços\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe3dcb",
   "metadata": {},
   "source": [
    "\n",
    "### 3.5. Alternative: Don't define individual rules, but rather one large regular expression\n",
    "\n",
    "<img src=\"img/alternative_for_portuguese.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e33c7",
   "metadata": {},
   "source": [
    "## 4. Regular expressions in xfst\n",
    "\n",
    "<i>Figures and tables taken from Beesley & Karttunen: Finite State Morphology, CSLI Publications, 2003.</i>\n",
    "\n",
    "### 4.1. Kleene (1956): Formal language theory\n",
    "\n",
    "<img src=\"img/kleene_formal_language_theory.png\">\n",
    "\n",
    "#### Examples (1)\n",
    "\n",
    "<img src=\"img/kleene_example_1.png\">\n",
    "\n",
    "#### Examples (2)\n",
    "\n",
    "<img src=\"img/kleene_example_2.png\">\n",
    "\n",
    "#### Examples (3)\n",
    "\n",
    "<img src=\"img/kleene_example_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e395a9",
   "metadata": {},
   "source": [
    "### 4.2. Writing regular expressions in xfst\n",
    "\n",
    "#### Writing regular expressions in xfst (1)\n",
    "\n",
    "```\n",
    "read regex d o g | c a t | h o r s e ;\n",
    "print words\n",
    "```\n",
    "\n",
    "Test by copying the above and giving it as input for interactive xfst program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import start_xfst\n",
    "start_xfst()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f0c096",
   "metadata": {},
   "source": [
    "Also test the examples given below. <b>NOTE: Do not start xfst shell if you already\n",
    "have an xfst shell running.</b> If you wish to start another shell, first exit\n",
    "the current shell with command `exit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc849905",
   "metadata": {},
   "source": [
    "#### Writing regular expressions in xfst (2)\n",
    "\n",
    "```\n",
    "read regex [ d o g | c a t | r a t | e l e p h a n t ] - [ d o g | r a t ];\n",
    "print words\n",
    "```\n",
    "\n",
    "#### Writing regular expressions in xfst (3)\n",
    "```\n",
    "read regex (r e)[[m a k e] | [c o m p i l e]]\n",
    "print words\n",
    "```\n",
    "\n",
    "It is a bit like writing a lexicon in xfst without using lexc.\n",
    "\n",
    "#### Writing regular expressions in xfst (4)\n",
    "\n",
    "```\n",
    "read regex a b c* d (e) f+ ;\n",
    "random-words\n",
    "```\n",
    "\n",
    "#### Writing regular expressions in xfst (5)\n",
    "\n",
    "```\n",
    "read regex [ g o:e o:e s e | m o:i u:0 s:c e | b o o k 0:s ] ;\n",
    "upper-words\n",
    "lower-words\n",
    "down mouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e6289",
   "metadata": {},
   "source": [
    "### 4.3. Summary: Regular expression syntax in xfst for repetition\n",
    "\n",
    "<img src=\"img/xfst_repetition.png\">\n",
    "\n",
    "#### Syntax for complement (= something other than)\n",
    "\n",
    "<img src=\"img/xfst_complement.png\">\n",
    "\n",
    "#### Writing regular expressions in xfst (6)\n",
    "\n",
    "```\n",
    "read regex [ b o b | j o b | r o b | k n o b ] .o. [ o -> u || \\[b | j | n] _ ];\n",
    "upper-words\n",
    "lower-words\n",
    "```\n",
    "\n",
    "#### Syntax for contain/ignore (= is part of)\n",
    "\n",
    "<img src=\"img/xfst_contain_ignore.png\">\n",
    "\n",
    "#### Writing regular expressions in xfst (7)\n",
    "\n",
    "```\n",
    "read regex [[t a l o | k y l ä | k o r i] s s A] .o. [ A -> a || $[a|o|u] ~$[ä|ö|y] _ ] .o. [ A -> ä ] ;\n",
    "upper-words\n",
    "lower-words\n",
    "```\n",
    "\n",
    "#### Writing regular expressions in xfst (8)\n",
    "\n",
    "```\n",
    "read regex [[{talo} | {kylä} | {kori}] {ssA}] .o. [ A -> a || $[a|o|u] ~$[ä|ö|y] _ ] .o. [ A -> ä ] ;\n",
    "upper-words\n",
    "lower-words\n",
    "```\n",
    "\n",
    "You can write a sequence of symbols, such as t a l o, together, if you enclose it in curly brackets: {talo}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6db2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_xfst()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9417ef",
   "metadata": {},
   "source": [
    "## 5. Pronunciation lexicon for a Language with Irregular Orthography: English\n",
    "\n",
    "<i>Figures taken from Jurafsky & Martin: Speech and Language Processing, Prentice Hall, 1999.</i>\n",
    "\n",
    "### 5.1. Symbol set for English pronunciation\n",
    "\n",
    "<img src=\"img/english_phonemes.png\">\n",
    "\n",
    "### 5.2. \"Two levels times two\"\n",
    "\n",
    "<ul>\n",
    " <li>We do not transduce between the orthographic form and the pronounced form.</li>\n",
    " <li>We transduce between the morphological lexical form and surface form (as earlier on this lecture).</li>\n",
    " <li>Every input and output symbol consists of two parts:</li>\n",
    " <ul>\n",
    "  <li>orthographic form</li>\n",
    "  <li>pronounced form</li>\n",
    "  <li>For instance: o|aa</li>\n",
    " </ul>\n",
    "</ul>\n",
    "\n",
    "<img src=\"img/two_levels_times_two.png\">\n",
    "\n",
    "### 5.3. Example entries from the noun stem lexicon\n",
    "\n",
    "<img src=\"img/example_entries.png\">\n",
    "\n",
    "### 5.4. Transducer for singular and plural inflection\n",
    "\n",
    "<img src=\"img/singular_and_plural_inflection.png\">\n",
    "\n",
    "### 5.5. Noun stems and inflections composed\n",
    "\n",
    "<img src=\"img/noun_stems_and_inflections_composed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932f4bc",
   "metadata": {},
   "source": [
    "## 6. Sound Change in Indo-European languages\n",
    "\n",
    "### 6.1. Research initiative\n",
    "\n",
    "<ul>\n",
    " <li>Creation of an interactive lexicon available on the Internet</li>\n",
    " <li>Using finite-state alternation rules to model sound change from Proto-Indo-European (PIE) to descendant languages</li>\n",
    " <li>HFST Foma engine (similar to HFST xfst)</li>\n",
    " <li>People</li>\n",
    " <ul>\n",
    "  <li>Jouna Pyysalo</li>\n",
    "  <li>Måns Huldén</li>\n",
    " </ul>\n",
    "<li><a href=\"http://pielexicon.hum.helsinki.fi/\">Project homepage</a></li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"img/pie_lexicon.png\">\n",
    "\n",
    "#### Example 1: Autumn, End\n",
    "\n",
    "<img src=\"img/autumn_end.png\">\n",
    "\n",
    "#### Example 2: Spring, Warmth\n",
    "\n",
    "<img src=\"img/spring_warmth.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c3ec0",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "<ul>\n",
    " <li>Selected parts of Chapter 2 and 3 of the Beesley & Karttunen book: “A Systematic Introduction” and “The xfst Interface”</li>\n",
    "</ul>\n",
    "\n",
    "## 7. Assignments\n",
    "\n",
    "### Assignment 5.1: Analysis of vocabularies\n",
    "\n",
    "The HFST project has produced open-source morphological analyzers for some languages.\n",
    "You can download them from <a href=\"https://korp.csc.fi/download/hfst-morphologies/\">Kielipankki (The Language Bank of Finland) pages</a>.\n",
    "\n",
    "<b>a.</b> Decide what language you want to work on.\n",
    "You can choose one of the following analyzers:\n",
    "<a href=\"https://korp.csc.fi/download/hfst-morphologies/en/wn-bnc/\">English</a>,\n",
    "<a href=\"https://korp.csc.fi/download/hfst-morphologies/fi/omorfi/\">Finnish</a>,\n",
    "<a href=\"https://korp.csc.fi/download/hfst-morphologies/test/fr/morphalou/\">French</a>,\n",
    "<a href=\"https://korp.csc.fi/download/hfst-morphologies/test/de/morphisto-smor/\">German</a>,\n",
    "<a href=\"https://korp.csc.fi/download/hfst-morphologies/sv/dsso/\">Swedish</a>,\n",
    "or <a href=\"https://korp.csc.fi/download/hfst-morphologies/test/tr/trmorph/\">Turkish</a>.\n",
    "\n",
    "Download the zip package, extract it, and search for file with extension `.hfst`. This is the analyzer file.\n",
    "\n",
    "<b>b.</b> Read the transducer from file and test it with HfstTransducer.read_from_file and HfstTransducer.lookup.\n",
    "Type in a few word forms and check what analyses you get for these word forms (the format of the tags is slightly different in the different languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201aa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # <write your solution here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de4942",
   "metadata": {},
   "source": [
    "Perform the same test in an interactive xfst shell (open it with with start_xfst). Use commands `load stack` and `lookup` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c171caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # <write your solution here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f656e6",
   "metadata": {},
   "source": [
    "<b>c.</b> Pick a text file containing words of the language you chose.\n",
    "There should be one word per line in the file.\n",
    "If you don’t have any text file available, you can use one of the pre-prepared files english-words.txt, finnish-words.txt, french-words.txt, german-words.txt or swedish-words.txt.\n",
    "For reading, you can use Python's `open(path,mode)` and `<file>.read()`, `<file>.readline()`, or `<file>.readlines()`.\n",
    "\n",
    "<b>d.</b> Run the entire text file through the analyzer, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dbb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <you must edit the code so that it will work for the language you have chosen>\n",
    "for line in some_text_file:\n",
    "    some_analyzer.lookup(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a549b1",
   "metadata": {},
   "source": [
    "<b>e.</b> Browse through the analyses of the words.\n",
    "Find a few words that are out-of-vocabulary, that is, the analyzer does not recognize them and cannot provide any analysis.\n",
    "Why aren't these words covered in the vocabulary of the analyzer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10a22a",
   "metadata": {},
   "source": [
    "### Assignment 5.2: Creating a translating guesser\n",
    "\n",
    "Your task is to create a guesser that translates words between related languages or dialects.\n",
    "For instance, in the attached file there is an example xfst script that translates English words ending in “-ity” to Swedish words ending in “-itet”.\n",
    "\n",
    "For instance,\n",
    "\n",
    "* down electricity produces elektricitet,\n",
    "* down university produces universitet, and\n",
    "* down popularity produces popularitet.\n",
    "\n",
    "You can solve this tasks in two ways:\n",
    "\n",
    "* either using only an xfst script as in English-to-Swedish translation example,\n",
    "* or using a lexc file in combination with an xfst script as in the Esperanto guesser (check lecture slides).\n",
    "\n",
    "If you use a lexc file you can do translation between suffixes of two languages in the continuation lexicons, such that the lexical form of a suffix is “ity” and its surface form is “itet”.\n",
    "\n",
    "* a. Choose the two languages you want to translate between.\n",
    "* b. You must have a regular expression that produces plausible words (or stems) in your source language.\n",
    "* c. Implement at least two translation rules (or equivalent translations in lexc).\n",
    "* d. You must test your system on at least five word forms and include the output of the test in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # <write your solution here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167fac7",
   "metadata": {},
   "source": [
    "### Assignment 5.3: Regular expressions\n",
    "\n",
    "In this assignment, you will practice writing regular expressions in xfst.\n",
    "Please note that in this assignment multicharacters are not allowed.\n",
    "\n",
    "1. Write regular expressions that denote languages which would accept:\n",
    "\n",
    "* a. union of the words: cat, cats, cat's, and cats'.\n",
    "* b. anything but the set of words: {sing, sang, sung}.\n",
    "* c. subtraction of the sets: {cat, dog, rat, mouse, cow} and {mouse, rat}.\n",
    "\n",
    "Run each regular expression in xfst shell with `read regex` command. After each regular expression run command `print net`.\n",
    "\n",
    "Next you will write regular expressions that contain composition with replace rules.\n",
    "\n",
    "2. Write an expression where an English verb vocabulary {sing, sit, ring, win} will be changed into past tense {sang, sat, rang, won}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0602282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # <write your solution here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4cf880",
   "metadata": {},
   "source": [
    "3. Write an expression where a set of Finnish words {makkara, hattara, jäkälä, läsnä} will be composed with rules that change a into ä, and ä into a,\n",
    "so that we get set {mäkkärä, hättärä, jakala, lasna} as final output. If you want, you can use parallel replace rules\n",
    "to solve this although they haven't been thought in the lectures (check the book for that), but also other solutions are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # <write your solution here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ef485",
   "metadata": {},
   "source": [
    "### Assignment 5.4: Drawing automata and transducers with hfst\n",
    "\n",
    "1. Draw union\n",
    "\n",
    "* a. Start xfst shell and run following commands:\n",
    "\n",
    "```\n",
    "read regex [ s i n g | s o n g | s i n g e r ] |  [ f l i n g | f i n g e r ] ;`\n",
    "view net\n",
    "```\n",
    "\n",
    "After you have done that, exit with `exit`.\n",
    "\n",
    "2. Following the same instructions, view images for regular expressions:\n",
    "\n",
    "* a. `{ready} .o. [ a |e | i |o | u ] -> %[ ... %]`\n",
    "* b. `(r e) [ [m a k e] | [c o m p i l e] ]`"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
