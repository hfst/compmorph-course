{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d711d0a5",
   "metadata": {},
   "source": [
    "# COMPUTATIONAL MORPHOLOGY WITH HFST TOOLS - LECTURE 2\n",
    "\n",
    "<ul>\n",
    "<li>1. <a href=\"#1.-Finite-State-Basics\">Finite-State Basics</a></li>\n",
    "<li>2. <a href=\"#2.-Set-Theory-for-Finite-State-Networks\">Set Theory for Finite-State Networks</a></li>\n",
    "<li>3. <a href=\"#3.-Item-&-Process-Morphology-Using-xfst-Rules\">Item & Process Morphology Using xfst Rules</a></li>\n",
    "<li>4. <a href=\"#4.-Example:-English-Adjectives\">Example: English Adjectives</a></li>\n",
    "<li>5. <a href=\"#5.-Assignments\">Assignments</li>\n",
    "</ul>\n",
    "\n",
    "## 1. Finite-State Basics\n",
    "\n",
    "### 1.1. Finite-State networks\n",
    "\n",
    "Recall the finite-state transducer (FST) for purely concatenative I&A (Item and Arrangement)\n",
    "English noun inflection from Lecture 1:\n",
    "\n",
    "<img src=\"img/noun_inflection.png\">\n",
    "\n",
    "The yellow circles represent _states_ or _nodes_ and the arrows represent _transitions_\n",
    "or _arcs_ between states. Each transition _consumes_ an input symbol and _produces_ an output symbol.\n",
    "The special symbol Îµ (_epsilon_) on the input side means that no symbol is consumed\n",
    "and on the output side that no symbol is produced when following a given transition.\n",
    "\n",
    "A finite-state network that has only input symbols in the transitions is called\n",
    "a finite-state automaton (FSA). It does not produce output, but merely recognizes\n",
    "(or rejects) input. Finite-state automaton for a 3-word language:\n",
    "\n",
    "<img src=\"img/three_word_language.png\">\n",
    "\n",
    "<ul>\n",
    "<li>Inputs to the automaton are <i>symbols</i> like: <code>m, e, c.</code></li>\n",
    "<li>The set of valid symbols that the automaton will accept is its <i>alphabet</i>: <code>{ a, c, e, g, i, m, n, o, r, s, t }</code>.</li>\n",
    "<li>The sequences of symbols that the automaton will accept are <i>words</i> like: <code>canto, mesa</code>.</li>\n",
    "<li>The entire set of words that the automaton accepts or recognizes is its <i>language</i>: <code>{ canto, mesa, tigre }</code>.</li>\n",
    "</ul>\n",
    "\n",
    "### 1.2. Sharing structure in minimal networks:\n",
    "\n",
    "<img src=\"img/fat_father.png\">\n",
    "\n",
    "<img src=\"img/clear_clever_ear_ever.png\">\n",
    "\n",
    "Removing a word from a minimal network may actually increase the size of the network!\n",
    "\n",
    "<img src=\"img/clear_clever_ever.png\">\n",
    "\n",
    "## 2. Set Theory for Finite-State Networks\n",
    "\n",
    "<i>Images from Beesley & Karttunen: Finite State Morphology, CSLI Publications, 2003.</i>\n",
    "\n",
    "### 2.1. Examples of sets:\n",
    "\n",
    "<img src=\"img/two_sets.png\">\n",
    "\n",
    "<img src=\"img/empty_set.png\">\n",
    "\n",
    "### 2.2. Some sets viewed as networks:\n",
    "\n",
    "<img src=\"img/empty_network.png\">\n",
    "\n",
    "<img src=\"img/empty_string_network.png\">\n",
    "\n",
    "### 2.3. Some infinite sets:\n",
    "\n",
    "<img src=\"img/zero_or_more_a.png\">\n",
    "\n",
    "<img src=\"img/universal_language.png\">\n",
    "\n",
    "### 2.4. Relations:\n",
    "\n",
    "<img src=\"img/lowercase2uppercase.png\">\n",
    "\n",
    "The example above shows an infinite relation containing pairs, such as\n",
    "<code>{<\"dog\",\"DOG\">,<\"cat\",\"CAT\">,<\"mouse\",\"MOUSE\">,...}</code>\n",
    "\n",
    "We can also have relations between lexical forms and surface forms, such as:\n",
    "<pre>\n",
    "{<\"cantar+Verb+PresInd+1P+Sg\", \"canto\">,\n",
    " <\"cantar+Verb+PresInd+1P+Pl\",\"cantamos\">,\n",
    " <\"canto+Noun+Masc+Sg\",\"canto\">, ...}\n",
    "</pre>\n",
    "\n",
    "### 2.5. Union of sets\n",
    "\n",
    "<img src=\"img/union_of_sets.png\">\n",
    "\n",
    "For instance, the union of the sets <code>{\"clear\", \"clever\", \"ear\", \"ever\"}</code> and <code>{\"fat\", \"father\"}</code> is\n",
    "<code>{\"clear\", \"clever\", \"ear\", \"ever\", \"fat\", \"father\"}</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import fst, disjunct\n",
    "set1 = fst(('clear','clever','ear','ever'))\n",
    "set2 = fst(('fat','father'))\n",
    "union_set = disjunct((set1, set2))\n",
    "print(union_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6ea18",
   "metadata": {},
   "source": [
    "The union shown as a network:\n",
    "\n",
    "<img src=\"img/union_of_sets_as_network.png\">\n",
    "\n",
    "### 2.6. Intersection of sets\n",
    "\n",
    "<img src=\"img/intersection_of_sets.png\">\n",
    "\n",
    "For instance, the intersection of sets <code>{\"clear\", \"clever\", \"ear\"}</code> and <code>{\"ear\", \"ever\"}</code> is <code>{\"ear\"}</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd54387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import intersect\n",
    "set1 = fst(('clear','clever','ear'))\n",
    "set2 = fst(('ear','ever'))\n",
    "intersection_set = intersect((set1, set2))\n",
    "print(intersection_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fc992",
   "metadata": {},
   "source": [
    "### 2.7. Subtraction of one set from another\n",
    "\n",
    "<img src=\"img/subtraction_of_sets.png\">\n",
    "\n",
    "For instance, the subtraction of sets <code>{\"clear\", \"clever\", \"ear\"}</code> and <code>{\"clever\", \"ear\"}</code> is <code>{\"clear\"}</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157204da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import subtract\n",
    "set1 = fst(('clear','clever','ear'))\n",
    "set2 = fst(('clever','ear'))\n",
    "subtraction_set = subtract((set1, set2))\n",
    "print(subtraction_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3dbed",
   "metadata": {},
   "source": [
    "### 2.8. Concatenation of sets\n",
    "\n",
    "<img src=\"img/concatenation_of_sets.png\">\n",
    "\n",
    "The concatenation is <code>{\"works\", \"working\", \"worked\"}</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import concatenate\n",
    "set1 = fst(('work'))\n",
    "set2 = fst(('s','ing','ed'))\n",
    "concatenation_set = concatenate((set1, set2))\n",
    "print(concatenation_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d82f0",
   "metadata": {},
   "source": [
    "### 2.9. Composition of transducers\n",
    "\n",
    "The composition of two relations is a relation that contains all such string pairs\n",
    "<A, C> where the first relation contains <A, B> and the second relation contains <B, C>.\n",
    "\n",
    "<img src=\"img/composition.png\">\n",
    "\n",
    "The composition of <code><\"cat\",\"chat\"></code> and <code><\"chat\",\"Katze\"></code> is <code>{<\"cat\",\"Katze\">}</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8924c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compose\n",
    "set1 = fst({'cat':'chat'})\n",
    "set2 = fst({'chat':'Katze'})\n",
    "composition_set = compose((set1, set2))\n",
    "print(composition_set.extract_paths(output='text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fe831",
   "metadata": {},
   "source": [
    "### 2.10. Projection\n",
    "\n",
    "<ul>\n",
    "<li>Projection is extracting one side of a relation.</li>\n",
    "<li>The upper/input projection of <code><\"cat\", \"CHAT\"></code> is \"cat\".</li>\n",
    "<li>The lower/output projection of <code><\"cat\", \"CHAT\"></code> is \"CHAT\".</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"img/projection.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3449aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = fst({'cat':'CHAT'})\n",
    "cat.input_project()\n",
    "cat.remove_epsilons() # get rid of epsilons\n",
    "print(cat.extract_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343fbce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "CHAT = fst({'cat':'CHAT'})\n",
    "CHAT.output_project()\n",
    "CHAT.remove_epsilons() # get rid of epsilons\n",
    "print(CHAT.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab07c23",
   "metadata": {},
   "source": [
    "### 2.11. Set operations expressed in the xfst language\n",
    "\n",
    "<table>\n",
    "<tr> <td><code>[ A | B ]</code></td> <td>denotes the union of the two languages or relations A and B (\"or\"-operation)</td> </tr>\n",
    "<tr> <td><code>[ A & B ]</code></td> <td>denotes the intersection (\"and\"-operation)</td> </tr>\n",
    "<tr> <td><code>[ A - B ]</code></td> <td>denotes the subtraction of B from A</td> </tr>\n",
    "<tr> <td><code>[ A B ]</code></td> <td>denotes the concatenation</td> </tr>\n",
    "<tr> <td><code>[ A .o. B ]</code></td> <td>denotes the composition of the relations</td> </tr>\n",
    "<tr> <td><code>A.u</code></td> <td>denotes the upper (i.e. input) projection</td> </tr>\n",
    "<tr> <td><code>A.l</code></td> <td>denotes the lower (o.e. output) projection</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce5762",
   "metadata": {},
   "source": [
    "## 3. Item & Process Morphology Using xfst Rules\n",
    "\n",
    "Recall the finite-state transducer for purely concatenative I&A English\n",
    "noun inflection (from previous lecture):\n",
    "\n",
    "<img src=\"img/noun_inflection.png\">\n",
    "\n",
    "A more compact finite-state transducer for I&P English noun inflection:\n",
    "\n",
    "<img src=\"img/noun_inflection_compact.png\">\n",
    "\n",
    "### 3.1. Cascade of transducers: Rule 1\n",
    "\n",
    "We will create a cascade of transducers, i.e. a set of transducers that will\n",
    "be applied in order to a given input. The output of one transducer will become\n",
    "the input of the next transducer until there are no more transducers in the cascade.\n",
    "The transducers apply morpholocial/phonological rules to their input one rule at a time.\n",
    "\n",
    "Insert 'e' after the end of the stem in front of 's', if the stem ends in\n",
    "'s', 'x', 'ch', 'sh' or 'y'.\n",
    "\n",
    "Expressed as an xfst rule:\n",
    "\n",
    "<code>define InsertE   [. .] -> e || [ s | x | c h | s h | y ] %^ _ s ;</code>\n",
    "\n",
    "When the rule is compiled to a transducer the result is as follows:\n",
    "\n",
    "<img src=\"img/InsertE.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc21b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import regex, HfstTransducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertE = regex(\"[. .] -> e || [ s | x | c h | s h | y ] %^ _ s\")\n",
    "print(InsertE.lookup(\"sky^s'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b987ef6",
   "metadata": {},
   "source": [
    "### 3.2. Cascade of transducers: Rule 2\n",
    "\n",
    "Rewrite 'y' as 'i' when followed by the end of the stem, which is\n",
    "further followed by 'e'.\n",
    "\n",
    "Expressed as an xfst rule:\n",
    "\n",
    "<code>define YToI    y -> i || _ %^ e ;</code>\n",
    "\n",
    "<img src=\"img/YToI.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389790d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "YToI = regex(\"y -> i || _ %^ e\")\n",
    "print(YToI.lookup(\"sky^es'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750ce88",
   "metadata": {},
   "source": [
    "### 3.3. Cascade of transducers: Rule 3\n",
    "\n",
    "Remove the end of stem marker\n",
    "\n",
    "Expressed as an xfst rule:\n",
    "\n",
    "<code>define CleanUp    %^ -> 0 ;</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanUp = regex(\"%^ -> 0\")\n",
    "print(CleanUp.lookup(\"ski^es'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075309b0",
   "metadata": {},
   "source": [
    "<img src=\"img/CleanUp.png\">\n",
    "\n",
    "### 3.4. Cascade equivalent to single FST\n",
    "\n",
    "<img src=\"img/cascade.png\">\n",
    "\n",
    "<i>Image from Beesley & Karttunen: Finite State Morphology, CSLI Publications, 2003.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf180e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_lexc_file\n",
    "lexicon = compile_lexc_file('en_ia_morphology.lexc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3960c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compose\n",
    "cascade = compose((lexicon, InsertE, YToI, CleanUp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bf8ad",
   "metadata": {},
   "source": [
    "When our lexicon is composed with our rules, we can actually produce one\n",
    "single FST and 'jump' from the lexical-form input straight to the final\n",
    "output in one go, without producing the intermediate steps.\n",
    "\n",
    "<pre>\n",
    "Example input:  sky+N+Pl+Poss\n",
    "Lexicon output: sky^s'\n",
    "Rule 1 output:  sky^es'\n",
    "Rule 2 output:  ski^es'\n",
    "Rule 3 output:  skies'\n",
    "</pre>\n",
    "\n",
    "The single FST will give directly: sky+N+Pl+Poss ð¡ skies'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cascade.lookup(\"sky+N+Pl+Poss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d54cd5",
   "metadata": {},
   "source": [
    "### 3.5. The order of the rules matters!\n",
    "\n",
    "What would happen if we reordered the rules (below) used in our simple\n",
    "English noun morphology?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edce55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = compose((lexicon,YToI, InsertE, CleanUp))\n",
    "print(cascade.lookup(\"sky+N+Pl+Poss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a5e53",
   "metadata": {},
   "source": [
    "### 3.6. xfst notation explained in context\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_1.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_2.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_3.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_4.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_5.png\">\n",
    "\n",
    "<i>Images from Beesley & Karttunen: Finite State Morphology, CSLI Publications, 2003.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939bbe4",
   "metadata": {},
   "source": [
    "## 4. Example: English Adjectives\n",
    "\n",
    "### 4.1. Lexicon (lexc) of some English adjectives\n",
    "\n",
    "The file `en_ip_adjectives_lexicon.lexc`\n",
    "\n",
    "<pre>\n",
    "Multichar_Symbols\n",
    "+A       ! Adjective tag\n",
    "+Pos     ! Positive\n",
    "+Cmp     ! Comparative\n",
    "+Sup     ! Superlative\n",
    "\n",
    "LEXICON Root\n",
    "Adjectives ;\n",
    "\n",
    "LEXICON Adjectives\n",
    "big     A ;\n",
    "cool    A ;\n",
    "crazy   A ;\n",
    "great   A ;\n",
    "grim    A ;\n",
    "happy   A ;\n",
    "hot     A ;\n",
    "long    A ;\n",
    "quick   A ;\n",
    "sad     A ;\n",
    "short   A ;\n",
    "slow    A ;\n",
    "small   A ;\n",
    "warm    A ;\n",
    "\n",
    "LEXICON A\n",
    "+A:^    Comparison ;\n",
    "\n",
    "LEXICON Comparison\n",
    "+Pos:0  # ;\n",
    "+Cmp:er # ;\n",
    "+Sup:est  # ;\n",
    "\n",
    "END \n",
    "</pre>\n",
    "\n",
    "### 4.2. Suggested xfst script for English adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93556c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_xfst_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_xfst_script(\"\"\"\n",
    "! Read lexicon and make a regex of it\n",
    "read lexc en_ip_adjectives_lexicon.lexc\n",
    "define Lexicon ;\n",
    "regex Lexicon ;\n",
    "\n",
    "! y/i alternation\n",
    "define YToI     y -> i || _ %^ e ;\n",
    "\n",
    "! Last rule cleans away the boundary marker\n",
    "define CleanUp  %^ -> 0 ;\n",
    "\n",
    "! Compose lexicon with rules\n",
    "regex Lexicon .o. YToI .o. CleanUp ;\n",
    "\n",
    "! Output all surface forms of the words\n",
    "lower-words\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e322fc",
   "metadata": {},
   "source": [
    "There are issues with some word forms...\n",
    "\n",
    "<pre>\n",
    "big         biger       bigest\n",
    "cool        cooler      coolest\n",
    "crazy       crazier     craziest\n",
    "great       greater     greatest\n",
    "grim        grimer      grimest\n",
    "happy       happier     happiest\n",
    "hot         hoter       hotest\n",
    "long        longer      longest\n",
    "quick       quicker     quickest\n",
    "sad         sader       sadest\n",
    "short       shorter     shortest\n",
    "slow        slower      slowest\n",
    "small       smaller     smallest\n",
    "warm        warmer      warmest\n",
    "</pre>\n",
    "\n",
    "### 4.3. Corrected xfst script for English adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a77ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_xfst_script(\"\"\"\n",
    "! Read lexicon and make a regex of it\n",
    "read lexc en_ip_adjectives_lexicon.lexc\n",
    "define Lexicon ;\n",
    "regex Lexicon ;\n",
    "\n",
    "define Vowel [ a | e | i | o | u | y ] ;\n",
    "define Cons  [ b | c | d | f | g | h | j | k | l | m |\n",
    "n | p | q | r | s | t | v | w | x | z ] ;\n",
    "\n",
    "! y/i alternation\n",
    "define YToI     y -> i || _ %^ e ;\n",
    "\n",
    "!++++++++++++++++++++++++++++++\n",
    "! Consonant reduplication\n",
    "define DoubleCons d -> d d ,\n",
    "g -> g g ,\n",
    "m -> m m ,\n",
    "t -> t t || Cons Vowel _ %^ e ;\n",
    "!++++++++++++++++++++++++++++++\n",
    "\n",
    "! Last rule cleans away the boundary marker\n",
    "define CleanUp  %^ -> 0 ;\n",
    "\n",
    "! Compose lexicon with rules\n",
    "regex Lexicon .o. YToI .o. DoubleCons .o. CleanUp ;\n",
    "\n",
    "! Output all surface forms of the words\n",
    "lower-words\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9ef90",
   "metadata": {},
   "source": [
    "Now it works!\n",
    "\n",
    "<pre>\n",
    "big        bigger      biggest\n",
    "cool       cooler      coolest\n",
    "crazy      crazier     craziest\n",
    "great      greater     greatest\n",
    "grim       grimmer     grimmest\n",
    "happy      happier     happiest\n",
    "hot        hotter      hottest\n",
    "long       longer      longest\n",
    "quick      quicker     quickest\n",
    "sad        sadder      saddest\n",
    "short      shorter     shortest\n",
    "slow       slower      slowest\n",
    "small      smaller     smallest\n",
    "warm       warmer      warmest\n",
    "</pre>\n",
    "\n",
    "## More information\n",
    "\n",
    "<ul>\n",
    "<li>Chapter 1 of the Beesley & Karttunen book: \"A Gentle Introduction\"</li>\n",
    "<li>Chapter 3 of the Beesley & Karttunen book: \"The xfst Interface\"</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2304a",
   "metadata": {},
   "source": [
    "## 5. Assignments\n",
    "\n",
    "### Assignment 2.1\n",
    "\n",
    "Add the following adjectives to en_ip_adjectives_lexicon.lexc: <tt>cute, nice, safe, wise</tt>.\n",
    "Then recompile the xfst script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_xfst_script(\"\"\"\n",
    "! Read lexicon and make a regex of it\n",
    "read lexc en_ip_adjectives_lexicon.lexc\n",
    "define Lexicon ;\n",
    "regex Lexicon ;\n",
    "\n",
    "define Vowel [ a | e | i | o | u | y ] ;\n",
    "define Cons  [ b | c | d | f | g | h | j | k | l | m |\n",
    "n | p | q | r | s | t | v | w | x | z ] ;\n",
    "\n",
    "! y/i alternation\n",
    "define YToI     y -> i || _ %^ e ;\n",
    "\n",
    "! Consonant reduplication\n",
    "define DoubleCons d -> d d ,\n",
    "g -> g g ,\n",
    "m -> m m ,\n",
    "t -> t t || Cons Vowel _ %^ e ;\n",
    "\n",
    "! Last rule cleans away the boundary marker\n",
    "define CleanUp  %^ -> 0 ;\n",
    "\n",
    "! Compose lexicon with rules\n",
    "regex Lexicon .o. YToI .o. DoubleCons .o. CleanUp ;\n",
    "\n",
    "! Output all surface forms of the words\n",
    "lower-words\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb72f4",
   "metadata": {},
   "source": [
    "Do you notice something strange with the words that you just added?\n",
    "Add a rule to fix them. (You can modify the script above.)\n",
    "\n",
    "Does it work now? If it does, write/copy your fixed xfst script to file en_ip_adjectives_rules_cascade.xfst.\n",
    "You will need it in the next assignment.\n",
    "\n",
    "Go to the browser tab where you chose this lecture (probably the tab on left side)\n",
    "and click <tt>New -> Text File</tt>. A new tab opens where you can edit\n",
    "the file (named untitled.txt by default). After you are finished, choose <tt>File -> Rename</tt> and\n",
    "rename the file to en_ip_adjectives_rules_cascade.xfst. Then click <tt>File -> Save</tt>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe1553",
   "metadata": {},
   "source": [
    "### Assignment 2.2: English adjectives with xfst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dbd075",
   "metadata": {},
   "source": [
    "Your task in this exercise is to test that the xfst script en_ip_adjectives_rules_cascade.xfst\n",
    "(the last version of the xfst script that you just copied to file) works as it should. This script runs inside start_xfst.\n",
    "\n",
    "Start interactive xfst shell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import start_xfst\n",
    "start_xfst()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67045cd3",
   "metadata": {},
   "source": [
    "You should see the prompt hfst[0]: appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b7dc4",
   "metadata": {},
   "source": [
    "Run the xfst script en_ip_adjectives_rules_cascade.xfst by typing:\n",
    "\n",
    "```\n",
    "source en_ip_adjectives_rules_cascade.xfst\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638336ff",
   "metadata": {},
   "source": [
    "The last command run by the script is `lower-words`, which shows the surface forms (âlower sideâ) of all words in your lexicon.\n",
    "Next, run the following commands and collect their outputs. Type in the commands after the hfst prompt.\n",
    "(After you are done  you can quit the xfst shell by typing `exit`.)\n",
    "\n",
    "* upper-words\n",
    "* random-upper (repeat this one a couple of times)\n",
    "* random-lower (repeat this one a couple of times)\n",
    "* longest-string\n",
    "* up shorter\n",
    "* down long+A+Sup\n",
    "\n",
    "Briefly describe in your own words what the six above commands do."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
